/*
 * Evaluations API
 *
 * API to create and evaluate custom challenges
 *
 * API version: 1.0.0
 * Generated by: Swagger Codegen (https://github.com/swagger-api/swagger-codegen.git)
 */

package aicrowd_evaluations

import (
	"time"
)

type Grader struct {
	// ID
	Id int32 `json:"id,omitempty"`
	// Creation time
	Created time.Time `json:"created,omitempty"`
	// Last updation time
	Updated time.Time `json:"updated,omitempty"`
	// S3 link of the Dataset
	DatasetUrl string `json:"dataset_url,omitempty"`
	// Cluster to run the grader on
	ClusterId int32 `json:"cluster_id,omitempty"`
	// Argo workflow template spec
	WorkflowSpec *interface{} `json:"workflow_spec,omitempty"`
	// Git URL of the repository containing the code that will be used for the evaluation
	EvaluatorRepo string `json:"evaluator_repo"`
	// Git branch/tag that should be used with the evaluator repository.
	EvaluatorRepoTag string `json:"evaluator_repo_tag,omitempty"`
	// Size of the dataset partition to request. Please provide at least 2x of the size of the dataset.
	StorageCapacity string `json:"storage_capacity,omitempty"`
	// Logs from argo workflow
	Logs *interface{} `json:"logs,omitempty"`
	// Additional meta data of the grader
	Meta *interface{} `json:"meta,omitempty"`
	// Status of the grader - True if it ready, False otherwise
	Status string `json:"status,omitempty"`
	// User ID
	UserId int32 `json:"user_id,omitempty"`
	// Organisation ID
	OrganisationId int32 `json:"organisation_id,omitempty"`
}
